{
 "cells": [
  {
   "cell_type": "raw",
   "id": "78a3ffdf-6f67-477d-b509-d0a5347350ad",
   "metadata": {},
   "source": [
    "This Jupyter NoteBook contain 3 sections:\n",
    "\n",
    "Section 1: Initial Code\n",
    "This section includes the initial python code that i started with.\n",
    "\n",
    "Section 2: Code Modification\n",
    "This section includes a the changes made on the code and the reasoning behind it.\n",
    "\n",
    "Section 3 : Final Result\n",
    "This section provides the final code retained for this function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62908c2d-840c-430c-96f9-b800d1aed5f1",
   "metadata": {},
   "source": [
    "SECTION 1: INITIAL CODE"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72a7daab-9c6c-4196-bd79-bd9aee63f1aa",
   "metadata": {},
   "source": [
    "I chose to start from scratch with simple code generated by prompts to some of the most widely used AI code generators. This approach provided me a valuable opportunity to put into practice the concepts Iâ€™ve recently learned and directly challenge my understanding of the material in real life scenario. Beginning with a simple straightforward baseline from the function description, and some researchs on similar scenarios, allowed me to build confidence and iteratively refine the solution, ensuring a deep grasp of the underlying problem and methods before moving on to more sophisticated techniques.\n",
    "This approach is used for all the functions in this Capstone Competition and provided good results for the majority of the functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdda21c5-037a-4409-9fcd-9273ead141cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters (highest output):\n",
      "param1    0.191597\n",
      "param2    0.252712\n",
      "param3    0.390953\n",
      "param4    0.229106\n",
      "param5    0.363287\n",
      "param6    0.861946\n",
      "output    2.114693\n",
      "Name: 70, dtype: float64\n",
      "Best hyperparameters from Bayesian Optimization:\n",
      "{'param1': 0.191597, 'param2': 0.252712, 'param3': 0.390953, 'param4': 0.229106, 'param5': 0.363287, 'param6': 0.861946}\n",
      "Predicted output: 1.9323146725336273\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "########################\n",
    "\n",
    "function = 7\n",
    "# Read the files\n",
    "X_init = np.load(\"initial_inputs.npy\")\n",
    "y_init = np.load(\"initial_outputs.npy\")\n",
    "queries_file = \"queries.txt\"\n",
    "observations_file = \"observations.txt\"\n",
    "\n",
    "# Read queries data\n",
    "import ast\n",
    "queries_data = []\n",
    "with open(queries_file, 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.replace('array(', 'np.array(')\n",
    "        queries_data.append(eval(line.strip()))\n",
    "\n",
    "# Read observations data\n",
    "observations_data = []\n",
    "with open(observations_file, 'r') as f:\n",
    "    for line in f:\n",
    "        observations_data.append(eval(line.strip()))\n",
    "\n",
    "# Extract the specified sub-arrays from queries\n",
    "X = np.array([q[function - 1] for q in queries_data], dtype='float64')\n",
    "y = np.array([o[function - 1] for o in observations_data])\n",
    "\n",
    "# Find and remove duplicates\n",
    "unique_indices = []\n",
    "seen = set()\n",
    "for i, x in enumerate(X):\n",
    "    x_tuple = tuple(x)  # Convert to tuple for hashability\n",
    "    if x_tuple not in seen:\n",
    "        seen.add(x_tuple)\n",
    "        unique_indices.append(i)\n",
    "\n",
    "# Keep only unique queries and observations\n",
    "X_unique = np.concatenate((X_init, X[unique_indices]))\n",
    "y_unique = np.concatenate((y_init, y[unique_indices]))\n",
    "queries_unique = [queries_data[i] for i in unique_indices]\n",
    "observations_unique = [observations_data[i] for i in unique_indices]\n",
    "\n",
    "# Save cleaned data to new files\n",
    "with open(\"queries_unique.txt\", \"w\") as f:\n",
    "    for query in queries_unique:\n",
    "        f.write(str(query) + \"\\n\")\n",
    "\n",
    "with open(\"observations_unique.txt\", \"w\") as f:\n",
    "    for obs in observations_unique:\n",
    "        f.write(str(obs) + \"\\n\")\n",
    "\n",
    "# Save cleaned numpy arrays\n",
    "np.save(\"initial_inputs_unique.npy\", X_unique)\n",
    "np.save(\"initial_outputs_unique.npy\", y_unique)\n",
    "#############################\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'param1': X_unique[:, 0],\n",
    "    'param2': X_unique[:, 1],\n",
    "    'param3': X_unique[:, 2],\n",
    "    'param4': X_unique[:, 3],\n",
    "    'param5': X_unique[:, 4],\n",
    "    'param6': X_unique[:, 5],\n",
    "    'output': y_unique\n",
    "})\n",
    "###########################\n",
    "\n",
    "# Find the row with the maximum output\n",
    "best_row_max = df.loc[df['output'].idxmax()]\n",
    "print(\"Best hyperparameters (highest output):\")\n",
    "print(best_row_max)\n",
    "####################\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Define the hyperparameter space\n",
    "space = [\n",
    "    Real(0.0, 1.0, name='param1'),\n",
    "    Real(0.0, 1.0, name='param2'),\n",
    "    Real(0.0, 1.0, name='param3'),\n",
    "    Real(0.0, 1.0, name='param4'),\n",
    "    Real(0.0, 1.0, name='param5'),\n",
    "    Real(0.0, 1.0, name='param6')\n",
    "]\n",
    "\n",
    "# Prepare data\n",
    "X = df[['param1', 'param2', 'param3', 'param4', 'param5', 'param6']].values\n",
    "y = df['output'].values\n",
    "\n",
    "# Train a surrogate model\n",
    "surrogate_model = RandomForestRegressor(n_estimators=150, random_state=42)\n",
    "surrogate_model.fit(X, y)\n",
    "\n",
    "# Define the objective function (negate output for maximization)\n",
    "def objective(params):\n",
    "    pred = surrogate_model.predict([params])[0]\n",
    "    return -pred  # Negate to maximize\n",
    "\n",
    "# Run Bayesian Optimization with corrected x0\n",
    "best_params_list = best_row_max[['param1', 'param2', 'param3', 'param4', 'param5', 'param6']].values.tolist()\n",
    "\n",
    "res = gp_minimize(\n",
    "    objective,\n",
    "    space,\n",
    "    n_calls=50,  # Number of evaluations\n",
    "    random_state=42,\n",
    "    x0=[best_params_list],  # Corrected: single list of 6 values\n",
    "    n_random_starts=10\n",
    ")\n",
    "\n",
    "# Best hyperparameters and predicted output\n",
    "best_params = dict(zip(['param1', 'param2', 'param3', 'param4', 'param5', 'param6'], res.x))\n",
    "print(\"Best hyperparameters from Bayesian Optimization:\")\n",
    "print(best_params)\n",
    "print(\"Predicted output:\", -res.fun)  # Negate back to get the actual output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d5b9ac-3665-4025-8831-8375036bd300",
   "metadata": {},
   "source": [
    "SECTION 2: CODE MODIFICATION"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6419facc-b2ff-4f79-b8b6-d6e9d150da51",
   "metadata": {},
   "source": [
    "As I'm tackling this Blackbox function optimization problem (Function 7), I started with a basic Bayesian optimization framework and iteratively refined it based on the results I observed and new techniques I learned along the way. The initial code provided a foundation, but it had several limitations that needed to be addressed to achieve better performance and a more robust solution.\n",
    "\n",
    "Initial Code: A Foundation with Gaps\n",
    "\n",
    "The initial code focused on:\n",
    "\n",
    "   Data Loading and Preprocessing: Loading initial data and cleaning query/observation data by removing duplicates.\n",
    "   Basic Bayesian Optimization Setup: Defining the hyperparameter space, training a `RandomForestRegressor` as a surrogate model, and using `gp_minimize` to find the best hyperparameters.\n",
    "   Finding the Best Initial Point: Using the best point from the initial dataset as a starting point for the optimization.\n",
    "\n",
    "However, the initial code lacked a crucial element: a reliable way to evaluate the actual performance of the optimized hyperparameters. It relied solely on the surrogate model's predictions, which could be inaccurate, especially in regions of the hyperparameter space that were not well-explored.\n",
    "\n",
    "The Evolution: Addressing Challenges and Improving Performance\n",
    "\n",
    "Here's a breakdown of the key changes I made and the reasoning behind them:\n",
    "\n",
    "1.  Introducing a Synthetic Dataset and `evaluate_actual_model` Function:\n",
    "\n",
    "       Change: I replaced the unknown Blackbox function with a simulated function based on a `RandomForestClassifier`. I also created an `evaluate_actual_model` function to evaluate the performance of the Random Forest Classifier with given hyperparameters.\n",
    "       Reason: Combination of both new material learned and results from the latest queries. The problem description hinted at leveraging existing knowledge (\"Sometimes Lazy is Best\"). I interpreted this as using a well-understood model (Random Forest) as a proxy for the Blackbox function. The `evaluate_actual_model` function provided a way to assess the true performance of the hyperparameters on this simulated function, rather than relying solely on the surrogate model. The latest queries showed that the surrogate model was not accurately predicting the performance, so I needed a more reliable evaluation method.\n",
    "       Engineering Perspective: This was a critical step. Without a way to evaluate the actual model, the optimization process was essentially blind. The synthetic dataset and `evaluate_actual_model` function provided a ground truth for evaluating the effectiveness of the optimization.\n",
    "\n",
    "2.  Data Cleaning (Duplicate Removal):\n",
    "\n",
    "       Change: Added `df.drop_duplicates` to remove duplicate rows from the DataFrame.\n",
    "       Reason: Based on results from the latest queries. I noticed that the surrogate model was being trained on redundant data, which could lead to overfitting and poor generalization. Removing duplicates ensured that the surrogate model was trained on a more diverse and representative dataset.\n",
    "       Engineering Perspective: Data quality is paramount. Removing duplicates improved the reliability of the surrogate model and prevented it from learning spurious patterns.\n",
    "\n",
    "3.  Latin Hypercube Sampling (LHS) for Active Learning:\n",
    "\n",
    "       Change: Implemented LHS to generate new hyperparameter samples around the current best point and evaluated these points using the `evaluate_actual_model` function.\n",
    "       Reason: Combination of both new material learned and results from the latest queries. I learned about active learning techniques, which strategically select new points to evaluate in order to improve the surrogate model. The latest queries showed that the optimization process was getting stuck in local optima. LHS allowed me to explore the hyperparameter space more efficiently and escape these local optima.\n",
    "       Engineering Perspective: This was a significant improvement. By actively selecting new points to evaluate, I was able to guide the optimization process towards more promising regions of the hyperparameter space. This significantly improved the efficiency of the optimization.\n",
    "\n",
    "4.  Refining the Objective Function:\n",
    "\n",
    "       Change: Used `skopt.utils.use_named_args` to make the objective function signature cleaner and more readable.\n",
    "       Reason: New material learned. This was primarily a code readability improvement. `use_named_args` made the code easier to understand and maintain.\n",
    "       Engineering Perspective: Code clarity is essential for collaboration and maintainability. This change improved the overall quality of the code.\n",
    "\n",
    "5.  Optimization Parameters:\n",
    "\n",
    "       Change: Adjusted the optimization parameters, such as the acquisition function (`acq_func='EI'`) and the exploration parameter (`xi=0.5`).\n",
    "       Reason: Based on results from the latest queries. I experimented with different optimization parameters to find the settings that worked best for this problem. The Expected Improvement (EI) acquisition function with a higher exploration parameter encouraged more exploration of the hyperparameter space.\n",
    "       Engineering Perspective: Fine-tuning the optimization parameters is crucial for achieving optimal performance. This required careful experimentation and analysis of the results.\n",
    "\n",
    "6.  Diagnostics and Validation:\n",
    "\n",
    "       Change: Added a convergence plot and calculated the number of unique points explored.\n",
    "       Reason: New material learned. These diagnostics provided valuable insights into the optimization process. The convergence plot showed how the objective function value improved over time, and the number of unique points explored indicated the diversity of the search.\n",
    "       Engineering Perspective: Monitoring the optimization process is essential for identifying potential problems and ensuring that the algorithm is converging correctly.\n",
    "\n",
    "Encountered Problems and Inconsistencies:\n",
    "\n",
    "Throughout this process, I encountered several challenges:\n",
    "\n",
    "   Surrogate Model Inaccuracy: The surrogate model was not always accurate, especially in regions of the hyperparameter space that were not well-explored. This led to the implementation of active learning techniques.\n",
    "   Local Optima: The optimization process often got stuck in local optima. This was addressed by using a higher exploration parameter and LHS.\n",
    "   Scaling the Accuracy Score: Scaling the accuracy score from the synthetic model to match the range of the original Blackbox function was a challenge. I had to make assumptions about the range of the accuracy score, which could have introduced some bias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9958d4e-68b3-43e4-a237-ae4652f75e98",
   "metadata": {},
   "source": [
    "SECTION 3: FINAL RESULT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a816efe2-db89-4250-b612-91999f4b79f4",
   "metadata": {},
   "source": [
    "In the final code section, although we did not have access to the actual scores, I meticulously kept records of the expected outputs from my code alongside the observed outputs from each submission. This comparison provided invaluable insights into the direction I needed to take and the changes that should be introduced. Through this process, I learned a great deal, with one of the most significant lessons being that the simplest approach is often the most effective. There is no need to complicate things unless absolutely necessary. If I had to start over and had more time, I would maintain the initial approach but also explore other coders' methods for inspiration, allowing me to experiment with more advanced techniques while still grounding my work in a solid foundational understanding.\n",
    "This approach was applied to all the functions in this Capstone Competition and it was very intuitive and valuable to see where I am without having access to the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59f66ee5-ca8b-4738-a0c9-a385f035f042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters (highest output):\n",
      "param1    0.191597\n",
      "param2    0.252712\n",
      "param3    0.390953\n",
      "param4    0.229106\n",
      "param5    0.363287\n",
      "param6    0.861946\n",
      "output    2.114693\n",
      "Name: 70, dtype: float64\n",
      "\n",
      "Best known point (best_row_max):\n",
      "      param1    param2    param3    param4    param5    param6    output\n",
      "70  0.191597  0.252712  0.390953  0.229106  0.363287  0.861946  2.114693\n",
      "\n",
      "Added 5 new points via LHS sampling\n",
      "Iteration No: 1 started. Evaluating function at provided point.\n",
      "Iteration No: 1 ended. Evaluation done at provided point.\n",
      "Time taken: 0.0045\n",
      "Function value obtained: -1.9497\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 0.0050\n",
      "Function value obtained: -0.2321\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 0.0078\n",
      "Function value obtained: -0.3352\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 0.0075\n",
      "Function value obtained: -0.1902\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 0.0071\n",
      "Function value obtained: -0.2638\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 0.0081\n",
      "Function value obtained: -0.4635\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 0.0053\n",
      "Function value obtained: -0.1318\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 0.0060\n",
      "Function value obtained: -0.2523\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 0.0040\n",
      "Function value obtained: -0.1146\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 0.0040\n",
      "Function value obtained: -0.7516\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 11 started. Evaluating function at random point.\n",
      "Iteration No: 11 ended. Evaluation done at random point.\n",
      "Time taken: 0.3457\n",
      "Function value obtained: -0.2796\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2189\n",
      "Function value obtained: -0.1674\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2589\n",
      "Function value obtained: -1.0774\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3189\n",
      "Function value obtained: -0.2382\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2621\n",
      "Function value obtained: -0.5382\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3349\n",
      "Function value obtained: -0.7008\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3105\n",
      "Function value obtained: -1.0613\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3151\n",
      "Function value obtained: -0.7672\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3707\n",
      "Function value obtained: -0.8579\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3141\n",
      "Function value obtained: -0.5784\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2061\n",
      "Function value obtained: -0.9244\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2737\n",
      "Function value obtained: -0.9635\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2778\n",
      "Function value obtained: -0.2828\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2260\n",
      "Function value obtained: -0.2566\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3050\n",
      "Function value obtained: -0.7462\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2986\n",
      "Function value obtained: -0.2892\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2898\n",
      "Function value obtained: -0.2108\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2283\n",
      "Function value obtained: -0.5771\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3737\n",
      "Function value obtained: -0.5912\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3428\n",
      "Function value obtained: -0.7379\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 31 started. Searching for the next optimal point.\n",
      "Iteration No: 31 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3346\n",
      "Function value obtained: -0.8957\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 32 started. Searching for the next optimal point.\n",
      "Iteration No: 32 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2683\n",
      "Function value obtained: -0.1504\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 33 started. Searching for the next optimal point.\n",
      "Iteration No: 33 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3511\n",
      "Function value obtained: -0.2473\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 34 started. Searching for the next optimal point.\n",
      "Iteration No: 34 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2722\n",
      "Function value obtained: -0.4451\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 35 started. Searching for the next optimal point.\n",
      "Iteration No: 35 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3069\n",
      "Function value obtained: -0.4913\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 36 started. Searching for the next optimal point.\n",
      "Iteration No: 36 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3188\n",
      "Function value obtained: -0.1722\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 37 started. Searching for the next optimal point.\n",
      "Iteration No: 37 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3325\n",
      "Function value obtained: -1.3596\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 38 started. Searching for the next optimal point.\n",
      "Iteration No: 38 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3921\n",
      "Function value obtained: -1.1554\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 39 started. Searching for the next optimal point.\n",
      "Iteration No: 39 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.4577\n",
      "Function value obtained: -1.1738\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 40 started. Searching for the next optimal point.\n",
      "Iteration No: 40 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3792\n",
      "Function value obtained: -0.0904\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 41 started. Searching for the next optimal point.\n",
      "Iteration No: 41 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3710\n",
      "Function value obtained: -0.8766\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 42 started. Searching for the next optimal point.\n",
      "Iteration No: 42 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3392\n",
      "Function value obtained: -0.9476\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 43 started. Searching for the next optimal point.\n",
      "Iteration No: 43 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3115\n",
      "Function value obtained: -0.2610\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 44 started. Searching for the next optimal point.\n",
      "Iteration No: 44 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3858\n",
      "Function value obtained: -0.8119\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 45 started. Searching for the next optimal point.\n",
      "Iteration No: 45 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3294\n",
      "Function value obtained: -0.2268\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 46 started. Searching for the next optimal point.\n",
      "Iteration No: 46 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.4161\n",
      "Function value obtained: -0.0909\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 47 started. Searching for the next optimal point.\n",
      "Iteration No: 47 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.2699\n",
      "Function value obtained: -0.3629\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 48 started. Searching for the next optimal point.\n",
      "Iteration No: 48 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3257\n",
      "Function value obtained: -0.1716\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 49 started. Searching for the next optimal point.\n",
      "Iteration No: 49 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.3006\n",
      "Function value obtained: -0.7754\n",
      "Current minimum: -1.9497\n",
      "Iteration No: 50 started. Searching for the next optimal point.\n",
      "Iteration No: 50 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.5052\n",
      "Function value obtained: -0.3745\n",
      "Current minimum: -1.9497\n",
      "\n",
      "Best Hyperparameters from Bayesian Optimization:\n",
      "{'param1': 0.191597, 'param2': 0.252712, 'param3': 0.390953, 'param4': 0.229106, 'param5': 0.363287, 'param6': 0.861946}\n",
      "Predicted Output: 1.949746003689904\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAGHCAYAAACZNGVOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABchklEQVR4nO3deVhV1f4/8PcRDzMcQWY9DKKJY4o4gH0TUxCHFLtZ5hSmqJkKalrYNVBD0syxVBwSy7Eyy8oIMqNUUDApRSQ1FI1BnBhE4Qj794c/9vXIdDYe5HB6v56H53Gvvdban+3Hrh/3XXttmSAIAoiIiIiISCPNGjsAIiIiIqKmhAU0EREREZEELKCJiIiIiCRgAU1EREREJAELaCIiIiIiCVhAExERERFJwAKaiIiIiEgCFtBERERERBKwgCYiIiIikoAFNBGRBv78809MnDgRbm5uMDY2hrm5OTw9PbF8+XLcvHmzscMjDUREREAmk4k/hoaGcHNzQ0hICG7fvi32i4mJgUwmw6VLlyRf4+DBg4iIiNBazESkm5o3dgBERLpu8+bNmD59Otq3b4958+ahY8eOUKlUSElJwcaNG5GYmIj9+/c3dpikodjYWCgUChQVFeHgwYNYs2YNTpw4gWPHjkEmkz3W3AcPHsTHH3/MIppIz7GAJiKqRWJiIl5//XX4+fnh66+/hpGRkXjOz88Pc+fORWxsbCNG+PjKy8tx//59tXvTZz169ICNjQ2ABzm8ceMGPvvsMxw7dgx9+/Zt5OiIqCngEg4iolosXboUMpkMmzZtqrbANDQ0xPDhw8XjiooKLF++HB4eHjAyMoKdnR0mTJiAq1evqo3z9fVF586dkZycjP/7v/+Dqakp2rRpg/fffx8VFRUAgPz8fBgaGmLhwoVVrnvu3DnIZDKsXbtWbMvNzcXUqVPRunVrcXnCokWLcP/+fbHPpUuXIJPJsHz5crz33ntwc3ODkZERDh8+DAD45ptv0LVrVxgZGaFNmzZYs2aNuPThYYIgYP369ejWrRtMTExgZWWFF198EX///bfk+6x0+/ZtzJ07F23atBF/74YMGYJz586JfcrKyvDee++Jv7+2traYOHEi8vPzq0+gBvr06QMAuHz5cq39PvnkEzz99NMwNjaGtbU1Ro4cifT0dPF8UFAQPv74YwBQWypSn6UgRKTjBCIiqtb9+/cFU1NToXfv3hqPmTJligBAmDFjhhAbGyts3LhRsLW1FZRKpZCfny/269evn9CyZUuhXbt2wsaNG4X4+Hhh+vTpAgBh+/btYr+RI0cKSqVSKC8vV7vO/PnzBUNDQ+H69euCIAhCTk6OoFQqBRcXFyE6Olr46aefhCVLlghGRkZCUFCQOC4zM1MAILRq1Uro37+/8OWXXwpxcXFCZmam8MMPPwjNmjUTfH19hf379wtffPGF0Lt3b8HV1VV49K+L4OBgQS6XC3PnzhViY2OFXbt2CR4eHoK9vb2Qm5sr+T4LCwuFTp06CWZmZsLixYuFH3/8Udi3b58QEhIi/Pzzz4IgCEJ5ebkQEBAgmJmZCYsWLRLi4+OFLVu2CK1atRI6duwolJSU1Jqb8PBwAYBaHgRBEGbPni0AEOLi4gRBEIRt27YJAITMzEyxz9KlSwUAwiuvvCJ8//33wqeffiq0adNGUCgUwl9//SUIgiBcuHBBePHFFwUAQmJiovhz7969WuMioqaHBTQRUQ1yc3MFAMLo0aM16p+eni4AEKZPn67Wfvz4cQGAsGDBArGtX79+AgDh+PHjan07duwoDBo0SDw+cOCAWnEnCA8KeycnJ+E///mP2DZ16lTB3NxcuHz5stp8K1asEAAIaWlpgiD8r4B2d3cXysrK1Pr27NlTUCqVQmlpqdhWVFQktGzZUq2ATkxMFAAIH374odr4K1euCCYmJsL8+fMl3+fixYsFAEJ8fLxQk927dwsAhH379qm1JycnCwCE9evX1zhWEP5XQOfm5goqlUq4deuWsGPHDsHExERQKpXC3bt3BUGoWkDfunVLMDExEYYMGaI2X1ZWlmBkZCSMGTNGbHvjjTeq/GODiPQPl3AQEWlJ5TKIoKAgtfZevXqhQ4cOOHTokFq7g4MDevXqpdbWtWtXtaUEgwcPhoODA7Zt2ya2/fjjj8jOzsZrr70mtn333Xfo378/nJyccP/+ffFn8ODBAICEhAS16wwfPhxyuVw8vnPnDlJSUhAYGAhDQ0Ox3dzcHM8//7za2O+++w4ymQzjxo1Tu5aDgwOefvpp/PLLL5Lv84cffsBTTz2FgQMHoibfffcdWrRogeeff17tut26dYODg0OV69bEwcEBcrkcVlZWGDduHDw9PREbGwtjY+Nq+ycmJuLu3btV8qpUKvHcc89VySsR6T++REhEVAMbGxuYmpoiMzNTo/43btwAADg6OlY55+TkVGWNbcuWLav0MzIywt27d8Xj5s2bY/z48Vi3bh1u376NFi1aICYmBo6Ojhg0aJDYLy8vD99++61aUfyw69evqx0/GuOtW7cgCALs7e2rjH20LS8vr8a+ANCmTRvJ95mfnw9nZ+dq53v4urdv31Yr8B/26D3W5KeffoJCoYBcLkfr1q2rje9hdeU1Pj5eo+sSkf5gAU1EVAMDAwMMGDAAP/zwA65evYrWrVvX2r+yEMvJyanSNzs7W9z5QaqJEyfigw8+wJ49e/Dyyy/jwIEDCA0NhYGBgdjHxsYGXbt2RWRkZLVzODk5qR0/+lKglZUVZDIZ8vLyqozNzc1VO7axsYFMJsNvv/1W7YuV9dnNw9bWtsqLlo+ysbFBy5Yta9z1xMLCQqNrPf3005Jy8XBeH/U4eSWipotLOIiIahEWFgZBEBAcHIyysrIq51UqFb799lsAwHPPPQcA2LFjh1qf5ORkpKenY8CAAfWKoUOHDujduze2bduGXbt2obS0FBMnTlTrM2zYMJw5cwbu7u7w8vKq8vNoAf0oMzMzeHl54euvv1a7z+LiYnz33XdVriUIAv75559qr9WlSxfJ9zh48GD89ddf+Pnnn2vsM2zYMNy4cQPl5eXVXrd9+/aSr6sJb29vmJiYVMnr1atX8fPPP6vltfIfDw8/XSci/cMn0EREtfD29saGDRswffp09OjRA6+//jo6deoElUqFU6dOYdOmTejcuTOef/55tG/fHlOmTMG6devQrFkzDB48GJcuXcLChQuhVCoxe/bsesfx2muvYerUqcjOzoaPj0+VYnHx4sWIj4+Hj48PZs2ahfbt2+PevXu4dOkSDh48iI0bN9b5BH3x4sUYOnQoBg0ahJCQEJSXl+ODDz6Aubm52tcW+/btiylTpmDixIlISUnBs88+CzMzM+Tk5ODIkSPo0qULXn/9dUn3Fxoair1792LEiBF4++230atXL9y9excJCQkYNmwY+vfvj9GjR2Pnzp0YMmQIQkJC0KtXL8jlcly9ehWHDx/GiBEjMHLkSEnX1USLFi2wcOFCLFiwABMmTMArr7yCGzduYNGiRTA2NkZ4eLjYt/IfD8uWLcPgwYNhYGCArl271rjshIiaqMZ9h5GIqGlITU0VXn31VcHZ2VkwNDQUzMzMhO7duwvvvvuucO3aNbFfeXm5sGzZMuGpp54S5HK5YGNjI4wbN064cuWK2nz9+vUTOnXqVOU6r776quDi4lKlvaCgQDAxMREACJs3b642xvz8fGHWrFmCm5ubIJfLBWtra6FHjx7CO++8IxQXFwuC8L9dOD744INq59i/f7/QpUsXwdDQUHB2dhbef/99YdasWYKVlVWVvp988onQu3dvwczMTDAxMRHc3d2FCRMmCCkpKfW6z1u3bgkhISGCs7OzIJfLBTs7O2Ho0KHCuXPnxD4qlUpYsWKF8PTTTwvGxsaCubm54OHhIUydOlU4f/58tfdUqaZt7B5V3TZ2giAIW7ZsEbp27SoYGhoKCoVCGDFihLi7SaXS0lJh8uTJgq2trSCTyaqdh4iaPpkgCEKjVvBERKSzVCoVunXrhlatWiEuLq6xwyEi0glcwkFERKJJkybBz88Pjo6OyM3NxcaNG5Geno41a9Y0dmhERDqDBTQREYmKiorw5ptvIj8/H3K5HJ6enjh48GCt+zMTEf3bcAkHEREREZEE3MaOiIiIiEgCFtBERERERBKwgCYiIiIikoAvET4hFRUVyM7OhoWFRZVP6BIRERFR4xMEAUVFRXByckKzZjU/Z2YB/YRkZ2dDqVQ2dhhEREREVIcrV67U+vVWFtBPiIWFBYAHCbG0tJQ8XqVSIS4uDv7+/pDL5doOj54g5lK/MJ/6g7nUH8yl/njSuSwsLIRSqRTrtpqwgH5CKpdtWFpa1ruANjU1haWlJf/HoIljLvUL86k/mEv9wVzqj8bKZV3LbfkSIRERERGRBCygiYiIiIgkYAFNRERERCQBC2giIiIiIgmaTAEdGRkJHx8fmJqaokWLFhqNKS4uxowZM9C6dWuYmJigQ4cO2LBhg1ofX19fyGQytZ/Ro0er9bl16xbGjx8PhUIBhUKB8ePH4/bt21q6MyIiIiJqSppMAV1WVoZRo0bh9ddf13jM7NmzERsbix07diA9PR2zZ8/GzJkz8c0336j1Cw4ORk5OjvgTHR2tdn7MmDFITU1FbGwsYmNjkZqaivHjx2vlvoiIiIioaWky29gtWrQIABATE6PxmMTERLz66qvw9fUFAEyZMgXR0dFISUnBiBEjxH6mpqZwcHCodo709HTExsYiKSkJvXv3BgBs3rwZ3t7eyMjIQPv27asdV1paitLSUvG4sLAQwIPtWFQqlcb3UKlyTH3Gkm5hLvUL86k/mEv9wVzqjyedS02v02QK6Pp45plncODAAbz22mtwcnLCL7/8gr/++gtr1qxR67dz507s2LED9vb2GDx4MMLDw8UNtBMTE6FQKMTiGQD69OkDhUKBY8eO1VhAR0VFiUX/w+Li4mBqalrve4qPj6/3WNItzKV+YT71B3OpP5hL/fGkcllSUqJRP70uoNeuXYvg4GC0bt0azZs3R7NmzbBlyxY888wzYp+xY8fCzc0NDg4OOHPmDMLCwvDHH3+IicrNzYWdnV2Vue3s7JCbm1vjtcPCwjBnzhzxuPLLNv7+/vX+kEp8fDz8/Py4KXwTx1zqF+ZTfzCX+oO51B9POpeVKwbq0qgFdERERLVPaR+WnJwMLy+ves2/du1aJCUl4cCBA3BxccGvv/6K6dOnw9HREQMHDgTwYP1zpc6dO6Ndu3bw8vLC77//Dk9PTwDVf41GEIRav1JjZGQEIyOjKu1yufyx/gA87njSHcylfmE+9QdzqT+YS/3xpHKp6TUatYCeMWNGlR0vHuXq6lqvue/evYsFCxZg//79GDp0KACga9euSE1NxYoVK8QC+lGenp6Qy+U4f/48PD094eDggLy8vCr98vPzYW9vX6/YiIiIiKjpatQC2sbGBjY2Ng0yd+XLes2aqW80YmBggIqKihrHpaWlQaVSwdHREQDg7e2NgoICnDhxAr169QIAHD9+HAUFBfDx8WmQ2ImIiIhIdzWZNdBZWVm4efMmsrKyUF5ejtTUVABA27ZtYW5uDgDw8PBAVFQURo4cCUtLS/Tr1w/z5s2DiYkJXFxckJCQgE8//RQrV64EAFy8eBE7d+7EkCFDYGNjg7Nnz2Lu3Lno3r07+vbtCwDo0KEDAgICEBwcLG5vN2XKFAwbNqzGFwiJiIiISH81mQL63Xffxfbt28Xj7t27AwAOHz4sblOXkZGBgoICsc+ePXsQFhaGsWPH4ubNm3BxcUFkZCSmTZsGADA0NMShQ4ewZs0aFBcXQ6lUYujQoQgPD4eBgYE4z86dOzFr1iz4+/sDAIYPH46PPvqooW+ZiIiIiHRQkymgY2Ji6twDWhAEtWMHBwds27atxv5KpRIJCQl1Xtva2ho7duzQKE4iIiIi0m9N5kuERERERES6gAU0EREREZEELKCJiIiIiCRgAU1EREREJAELaCIiIiIiCVhAExERERFJwAKaiIiIiEgCFtBERERERBKwgCYiIiIikoAFNBERERGRBCygiYiIiIgkYAFNRERERCQBC2giIiIiIglYQBMRERERScACmoiIiIhIAhbQREREREQSsIAmIiIiIpKABTQRERERkQQsoImIiIiIJGABTUREREQkAQtoIiIiIiIJWEATEREREUnAApqIiIiISAIW0EREREREEjSZAjoyMhI+Pj4wNTVFixYtNBpTXFyMGTNmoHXr1jAxMUGHDh2wYcMG8fylS5cgk8mq/fniiy/Efq6urlXOv/3229q+RSIiIiJqApo3dgCaKisrw6hRo+Dt7Y2tW7dqNGb27Nk4fPgwduzYAVdXV8TFxWH69OlwcnLCiBEjoFQqkZOTozZm06ZNWL58OQYPHqzWvnjxYgQHB4vH5ubmj39TRERERNTkNJkCetGiRQCAmJgYjcckJibi1Vdfha+vLwBgypQpiI6ORkpKCkaMGAEDAwM4ODiojdm/fz9efvnlKgWyhYVFlb5ERERE9O/TZAro+njmmWdw4MABvPbaa3BycsIvv/yCv/76C2vWrKm2/8mTJ5GamoqPP/64yrlly5ZhyZIlUCqVGDVqFObNmwdDQ8Mar11aWorS0lLxuLCwEACgUqmgUqkk30vlmPqMJd3CXOoX5lN/MJf6g7nUH086l5peR68L6LVr1yI4OBitW7dG8+bN0axZM2zZsgXPPPNMtf23bt2KDh06wMfHR609JCQEnp6esLKywokTJxAWFobMzExs2bKlxmtHRUWJT80fFhcXB1NT03rfU3x8fL3Hkm5hLvUL86k/mEv9wVzqjyeVy5KSEo36SSqgMzIysHv3bvz222+4dOkSSkpKYGtri+7du2PQoEH4z3/+AyMjI43ni4iIqLbIfFhycjK8vLykhClau3YtkpKScODAAbi4uODXX3/F9OnT4ejoiIEDB6r1vXv3Lnbt2oWFCxdWmWf27Nnir7t27QorKyu8+OKLWLZsGVq2bFnttcPCwjBnzhzxuLCwEEqlEv7+/rC0tJR8LyqVCvHx8fDz84NcLpc8nnQHc6lfmE/9wVzqD+ZSfzzpXFauGKiLRgX0qVOnMH/+fPz222/w8fFBr169EBgYCBMTE9y8eRNnzpzBO++8g5kzZ2L+/PkIDQ3VqJCeMWMGRo8eXWsfV1dXjW7kUXfv3sWCBQuwf/9+DB06FMCD4jc1NRUrVqyoUkB/+eWXKCkpwYQJE+qcu0+fPgCACxcu1FhAGxkZVft7IJfLH+sPwOOOJ93BXOoX5lN/MJf6g7nUH08ql5peQ6MCOjAwEPPmzcPevXthbW1dY7/ExESsWrUKH374IRYsWFDnvDY2NrCxsdEoUKkq1xo3a6a+U5+BgQEqKiqq9N+6dSuGDx8OW1vbOuc+deoUAMDR0VE7wRIRERFRk6FRAX3+/PlaX5ir5O3tDW9vb5SVlT12YI/KysrCzZs3kZWVhfLycqSmpgIA2rZtK+6Y4eHhgaioKIwcORKWlpbo168f5s2bBxMTE7i4uCAhIQGffvopVq5cqTb3hQsX8Ouvv+LgwYNVrpuYmIikpCT0798fCoUCycnJmD17NoYPHw5nZ2et3ycRERER6TaNCmhNiufH6a+Jd999F9u3bxePu3fvDgA4fPiwuE1dRkYGCgoKxD579uxBWFgYxo4di5s3b8LFxQWRkZGYNm2a2tyffPIJWrVqBX9//yrXNTIywt69e7Fo0SKUlpbCxcUFwcHBmD9/vtbvkYiIiIh0n0YF9Nq1azWecNasWfUOpjYxMTF17gEtCILasYODA7Zt21bn3EuXLsXSpUurPefp6YmkpCSN4yQiIiIi/aZRAb1q1Sq14/z8fJSUlIif1L59+zZMTU1hZ2fXYAU0EREREZEuaFZ3FyAzM1P8iYyMRLdu3ZCeno6bN2/i5s2bSE9Ph6enJ5YsWdLQ8RIRERERNSqNCuiHLVy4EOvWrUP79u3Ftvbt22PVqlX473//q9XgiIiIiIh0jeQCOicnp9rPHJaXlyMvL08rQRERERER6SrJBfSAAQMQHByMlJQU8aW9lJQUTJ06tcrHSYiIiIiI9I3kArpyy7devXrB2NgYRkZG6N27NxwdHbFly5aGiJGIiIiISGdotAvHw2xtbXHw4EH89ddfOHfuHARBQIcOHfDUU081RHxERERERDpFcgFdydXVFYIgwN3dHc2b13saIiIiIqImRfISjpKSEkyaNAmmpqbo1KkTsrKyADz4gMr777+v9QCJiIiIiHSJ5AI6LCwMf/zxB3755RcYGxuL7QMHDsTevXu1GhwRERERka6RvPbi66+/xt69e9GnTx/IZDKxvWPHjrh48aJWgyMiIiIi0jWSn0Dn5+fDzs6uSvudO3fUCmoiIiIiIn0kuYDu2bMnvv/+e/G4smjevHkzvL29tRcZEREREZEOkryEIyoqCgEBATh79izu37+PNWvWIC0tDYmJiUhISGiIGImIiIiIdIbkJ9A+Pj44evQoSkpK4O7ujri4ONjb2yMxMRE9evRoiBiJiIiIiHRGvTZw7tKlC7Zv367tWIiIiIiIdJ7kJ9AGBga4du1alfYbN27AwMBAK0EREREREekqyQW0IAjVtpeWlsLQ0PCxAyIiIiIi0mUaL+FYu3YtgAe7bmzZsgXm5ubiufLycvz666/w8PDQfoRERERERDpE4wJ61apVAB48gd64caPacg1DQ0O4urpi48aN2o+QiIiIiEiHaFxAZ2ZmAgD69++Pr776ClZWVg0WFBERERGRrpK8C8fhw4cbIg4iIiIioiahXtvYXb16FQcOHEBWVhbKysrUzq1cuVIrgRERERER6SLJBfShQ4cwfPhwuLm5ISMjA507d8alS5cgCAI8PT0bIkYiIiIiIp0heRu7sLAwzJ07F2fOnIGxsTH27duHK1euoF+/fhg1alRDxEhEREREpDMkF9Dp6el49dVXAQDNmzfH3bt3YW5ujsWLF2PZsmVaD7BSZGQkfHx8YGpqihYtWmg0Ji8vD0FBQXBycoKpqSkCAgJw/vx5tT6lpaWYOXMmbGxsYGZmhuHDh+Pq1atqfW7duoXx48dDoVBAoVBg/PjxuH37tpbujIiIiIiaEskFtJmZGUpLSwEATk5OuHjxonju+vXr2ovsEWVlZRg1ahRef/11jfoLgoDAwED8/fff+Oabb3Dq1Cm4uLhg4MCBuHPnjtgvNDQU+/fvx549e3DkyBEUFxdj2LBhKC8vF/uMGTMGqampiI2NRWxsLFJTUzF+/Hit3yMRERER6T7Ja6D79OmDo0ePomPHjhg6dCjmzp2L06dP46uvvkKfPn0aIkYAwKJFiwAAMTExGvU/f/48kpKScObMGXTq1AkAsH79etjZ2WH37t2YPHkyCgoKsHXrVnz22WcYOHAgAGDHjh1QKpX46aefMGjQIKSnpyM2NhZJSUno3bs3AGDz5s3w9vZGRkYG2rdvr/2bJSIiIiKdJbmAXrlyJYqLiwEAERERKC4uxt69e9G2bVvxYyu6oPIpubGxsdhmYGAAQ0NDHDlyBJMnT8bJkyehUqng7+8v9nFyckLnzp1x7NgxDBo0CImJiVAoFGLxDDz4R4RCocCxY8dqLKBLS0vFGACgsLAQAKBSqaBSqSTfT+WY+owl3cJc6hfmU38wl/qDudQfTzqXml5HcgHdpk0b8dempqZYv3691CmeCA8PD7i4uCAsLAzR0dEwMzPDypUrkZubi5ycHABAbm4uDA0Nq3wUxt7eHrm5uWIfOzu7KvPb2dmJfaoTFRUlPjV/WFxcHExNTet9X/Hx8fUeS7qFudQvzKf+YC71B3OpP55ULktKSjTqV699oLUlIiKi2iLzYcnJyfDy8pI8t1wux759+zBp0iRYW1vDwMAAAwcOxODBg+scKwgCZDKZePzwr2vq86iwsDDMmTNHPC4sLIRSqYS/vz8sLS0l3s2DfxHFx8fDz88Pcrlc8njSHcylfmE+9QdzqT+YS/3xpHNZuWKgLpILaCsrq2oLR5lMBmNjY7Rt2xZBQUGYOHFinXPNmDEDo0ePrrWPq6ur1BBFPXr0QGpqKgoKClBWVgZbW1v07t1bLMgdHBxQVlaGW7duqT2FvnbtGnx8fMQ+eXl5VebOz8+Hvb19jdc2MjKCkZFRlXa5XP5YfwAedzzpDuZSvzCf+oO51B/Mpf54UrnU9BqSC+h3330XkZGRGDx4MHr16gVBEJCcnIzY2Fi88cYbyMzMxOuvv4779+8jODi41rlsbGxgY2MjNQTJFAoFgAcvFqakpGDJkiUAHhTYcrkc8fHxeOmllwAAOTk5OHPmDJYvXw4A8Pb2RkFBAU6cOIFevXoBAI4fP46CggKxyCYiIiKifw/JBfSRI0fw3nvvYdq0aWrt0dHRiIuLw759+9C1a1esXbu2zgJaiqysLNy8eRNZWVkoLy9HamoqAKBt27YwNzcH8GDdc1RUFEaOHAkA+OKLL2BrawtnZ2ecPn0aISEhCAwMFF8aVCgUmDRpEubOnYuWLVvC2toab775Jrp06SLuytGhQwcEBAQgODgY0dHRAIApU6Zg2LBh3IGDiIiI6F9I8j7QP/74o1hcPmzAgAH48ccfAQBDhgzB33///fjRPeTdd99F9+7dER4ejuLiYnTv3h3du3dHSkqK2CcjIwMFBQXicU5ODsaPHw8PDw/MmjUL48ePx+7du9XmXbVqFQIDA/HSSy+hb9++MDU1xbfffgsDAwOxz86dO9GlSxf4+/vD398fXbt2xWeffabV+yMiIiKipkHyE2hra2t8++23mD17tlr7t99+C2trawDAnTt3YGFhoZ0I/7+YmJg694AWBEHteNasWZg1a1atY4yNjbFu3TqsW7euxj7W1tbYsWOHxrESERERkf6SXEAvXLgQr7/+Og4fPoxevXpBJpPhxIkTOHjwIDZu3AjgwVYj/fr103qwRERERESNTXIBHRwcjI4dO+Kjjz7CV199BUEQ4OHhgYSEBPGlurlz52o9UCIiIiIiXVCvfaD79u2Lvn37ajsWIiIiIiKdJ/klQgC4ePEi/vvf/2LMmDG4du0aACA2NhZpaWlaDY6IiIiISNdILqATEhLQpUsXHD9+HPv27UNxcTEA4M8//0R4eLjWAyQiIiIi0iWSC+i3334b7733HuLj42FoaCi29+/fH4mJiVoNjoiIiIhI10guoE+fPi1+qORhtra2uHHjhlaCIiIiIiLSVZIL6BYtWiAnJ6dK+6lTp9CqVSutBEVEREREpKskF9BjxozBW2+9hdzcXMhkMlRUVODo0aN48803MWHChIaIkYiIiIhIZ0guoCMjI+Hs7IxWrVqhuLgYHTt2xLPPPgsfHx/897//bYgYiYiIiIh0huR9oOVyOXbu3InFixfj1KlTqKioQPfu3dGuXbuGiI+IiIiISKfU60MqAODu7g53d3dtxkJEREREpPM0LqAXL16sUb9333233sEQEREREek6jQvo/fv313hOJpMhIyMD9+7dYwFNRERERHpN4wL61KlT1banpqbi7bffxpkzZxAcHKy1wIiIiIiIdJHkXTgqZWZmYty4cejZsycUCgXS0tKwceNGbcZGRERERKRzJBfQ169fx8yZM+Hh4YGcnBwcO3YMe/fu5S4cRERERPSvoPESjjt37mDFihVYuXIl2rZti2+//Rb+/v4NGRsRERERkc7RuIB2d3dHUVERZs6ciVdeeQUymQx//vlnlX5du3bVaoBERERERLpE4wL62rVrAIDly5fjgw8+gCAI4jmZTAZBECCTyVBeXq79KImIiIiIdITGBXRmZmZDxkFERERE1CRoXEC7uLg0ZBxERERERE2CRrtwZGVlSZr0n3/+qVcwRERERES6TqMCumfPnggODsaJEydq7FNQUIDNmzejc+fO+Oqrr7QWIBERERGRLtFoCUd6ejqWLl2KgIAAyOVyeHl5wcnJCcbGxrh16xbOnj2LtLQ0eHl54YMPPsDgwYMbOm4iIiIiokah0RNoa2trrFixAtnZ2diwYQOeeuopXL9+HefPnwcAjB07FidPnsTRo0cbrHiOjIyEj48PTE1N0aJFC43G5OXlISgoCE5OTjA1NUVAQIAYMwDcvHkTM2fORPv27WFqagpnZ2fMmjULBQUFavO4urpCJpOp/bz99tvavD0iIiIiaiI0fokQAIyNjfHCCy/ghRdeaKh4alRWVoZRo0bB29sbW7durbO/IAgIDAyEXC7HN998A0tLS6xcuRIDBw7E2bNnYWZmhuzsbGRnZ2PFihXo2LEjLl++jGnTpiE7Oxtffvml2nyLFy9GcHCweGxubq71eyQiIiIi3SepgG5MixYtAgDExMRo1P/8+fNISkrCmTNn0KlTJwDA+vXrYWdnh927d2Py5Mno3Lkz9u3bJ45xd3dHZGQkxo0bh/v376N58//99lhYWMDBwUF7N0RERERETVKTKaClKi0tBfDgqXklAwMDGBoa4siRI5g8eXK14woKCmBpaalWPAPAsmXLsGTJEiiVSowaNQrz5s2DoaFhrdevjAEACgsLAQAqlQoqlUry/VSOqc9Y0i3MpX5hPvUHc6k/mEv98aRzqel19LaA9vDwgIuLC8LCwhAdHQ0zMzOsXLkSubm5yMnJqXbMjRs3sGTJEkydOlWtPSQkBJ6enrCyssKJEycQFhaGzMxMbNmypcbrR0VFiU/NHxYXFwdTU9N631d8fHy9x5JuYS71C/OpP5hL/cFc6o8nlcuSkhKN+smEh7/J/YRFRERUW2Q+LDk5GV5eXuJxTEwMQkNDcfv27TrnP3nyJCZNmoQ//vgDBgYGGDhwIJo1e/De5MGDB9X6FhYWwt/fH1ZWVjhw4ADkcnmN8+7btw8vvvgirl+/jpYtW1bbp7on0EqlEtevX4elpWWdsT9KpVIhPj4efn5+tcZGuo+51C/Mp/5gLvUHc6k/nnQuCwsLYWNjI65IqEmjPoGeMWMGRo8eXWsfV1fXes/fo0cPpKamoqCgAGVlZbC1tUXv3r3VCnIAKCoqQkBAAMzNzbF///46E9SnTx8AwIULF2osoI2MjGBkZFSlXS6XP9YfgMcdT7qDudQvzKf+YC71B3OpP55ULjW9Rr0K6M8++wwbN25EZmYmEhMT4eLigtWrV8PNzQ0jRozQeB4bGxvY2NjUJwRJFAoFgAcvFqakpGDJkiXiucLCQgwaNAhGRkY4cOCA2prpmpw6dQoA4Ojo2DABExEREZHO0mgf6Idt2LABc+bMwZAhQ3D79m2Ul5cDAFq0aIHVq1drOz5RVlYWUlNTkZWVhfLycqSmpiI1NRXFxcViHw8PD+zfv188/uKLL/DLL7/g77//xjfffAM/Pz8EBgbC398fwIMnz/7+/rhz5w62bt2KwsJC5ObmIjc3V7yvxMRErFq1CqmpqcjMzMTnn3+OqVOnYvjw4XB2dm6w+yUiIiIi3ST5CfS6deuwefNmBAYG4v333xfbvby88Oabb2o1uIe9++672L59u3jcvXt3AMDhw4fh6+sLAMjIyFD7CEpOTg7mzJmDvLw8ODo6YsKECVi4cKF4/uTJkzh+/DgAoG3btmrXy8zMhKurK4yMjLB3714sWrQIpaWlcHFxQXBwMObPn99Qt0pEREREOkxyAZ2ZmSkWrw8zMjLCnTt3tBJUdWJiYurcA/rR9yFnzZqFWbNm1djf19e3yphHeXp6IikpSeM4iYiIiEi/SV7C4ebmhtTU1CrtP/zwAzp27KiNmIiIiIiIdJbkJ9Dz5s3DG2+8gXv37kEQBJw4cQK7d+9GVFRUrfsiExERERHpA8kF9MSJE3H//n3Mnz8fJSUlGDNmDFq1aoU1a9bUuSUdEREREVFTV69t7IKDgxEcHIzr16+joqICdnZ22o6LiIiIiEgnPdaHVJ7EHs5ERERERLpEcgHt5uYGmUxW4/m///77sQIiIiIiItJlkgvo0NBQtWOVSoVTp04hNjYW8+bN01ZcREREREQ6SXIBHRISUm37xx9/jJSUlMcOiIiIiIhIl0neB7omgwcPxr59+7Q1HRERERGRTtJaAf3ll1/C2tpaW9MREREREekkyUs4unfvrvYSoSAIyM3NRX5+PtavX6/V4IiIiIiIdI3kAjowMFDtuFmzZrC1tYWvry88PDy0FRcRERERkU6SXECHh4c3RBxERERERE2CRgV0YWGhxhNaWlrWOxgiIiIiIl2nUQHdokWLWj+eAjxYCy2TyVBeXq6VwIiIiIiIdJFGBfThw4cbOg4iIiIioiZBowK6X79+DR0HEREREVGTIPklwkolJSXIyspCWVmZWnvXrl0fOygiIiIiIl0luYDOz8/HxIkT8cMPP1R7nmugiYiIiEifSf4SYWhoKG7duoWkpCSYmJggNjYW27dvR7t27XDgwIGGiJGIiIiISGdIfgL9888/45tvvkHPnj3RrFkzuLi4wM/PD5aWloiKisLQoUMbIk4iIiIiIp0g+Qn0nTt3YGdnBwCwtrZGfn4+AKBLly74/ffftRsdEREREZGOkVxAt2/fHhkZGQCAbt26ITo6Gv/88w82btwIR0dHrQdIRERERKRLJC/hCA0NRU5ODoAHn/UeNGgQdu7cCUNDQ8TExGg7PiIiIiIinaJxAR0YGIjJkyfjlVdeQbNmDx5cd+/eHZcuXcK5c+fg7OwMGxubBguUNFdeXoE/0q/ixq07aGllhqc7tIaBQfX/Z4OUvpxbO3Onpl1FemYRnNKuwrOLS5OJu6Hm1qVY6jO3pvnUtbg5d9X+zKX+zM1c6s/cUv7OfJJkgiAImnQcNGgQDh06BDs7OwQFBWHixIlo165dQ8cnioyMxPfff4/U1FQYGhri9u3bdY7Jy8vDW2+9hbi4ONy+fRvPPvss1q1bpxa3r68vEhIS1Ma9/PLL2LNnj3h869YtzJo1S9xlZPjw4Vi3bh1atGihcfyFhYVQKBQoKCiApaWlxuMqqVQqHDx4EEOGDIFcLq+xX0LSX1j9yc/Iv1Esttm2NEfoa8+hX5+n6t2Xc3Puhphbl2Lh3Jybc3Nuzt0059YmTes1jQtoALh69Sq2bduG7du3IzMzE3379sXkyZMxatQomJiYaCXwmoSHh6NFixa4evUqtm7dWmcBLQgCfHx8IJfL8eGHH8LS0hIrV65EbGwszp49CzMzMwAPCuinnnoKixcvFseamJhAoVCIx4MHD8bVq1exadMmAMCUKVPg6uqKb7/9VuP4n0QBnZD0F975oOatBCPnDRf/0Enpy7k5d0PMrUuxcG7Ozbk5N+dumnNrm6b1mqTn4K1bt8bChQtx4cIF/PTTT3BxccH06dPh4OCAqVOn4vjx448deE0WLVqE2bNno0uXLhr1P3/+PJKSkrBhwwb07NkT7du3x/r161FcXIzdu3er9TU1NYWDg4P483DxnJ6ejtjYWGzZsgXe3t7w9vbG5s2b8d1334kvU+qC8vIKrP7k51r7rPnkMMrLKyT15dycuyHm1qVYODfn5tycm3M3zbkbk6Qn0NUpKirCrl27sGDBAhQUFOD+/fvaiq1aMTExCA0NrfMJ9OnTp9G1a1dcuHAB7u7uYrujoyMGDRokvvDo6+uLtLQ0CIIAe3t7DB48GOHh4bCwsAAAfPLJJ5gzZ06V67Vo0QKrVq3CxIkTq71+aWkpSktLxePCwkIolUpcv3693k+g4+Pj4efnV+0T6NS0q5i9ZF+d81haGD+Ip+ieRn0N5c1RprqvcX/OzbmbWiycm3Nzbs7NuZve3KsW/gfdOrWus59UhYWFsLGxqfMJtORdOB72999/IyYmBjExMSgoKMDAgQMfZzqt8vDwgIuLC8LCwhAdHQ0zMzOsXLkSubm54i4iADB27Fi4ubnBwcEBZ86cQVhYGP744w/Ex8cDAHJzc8V9rx9mZ2eH3NzcGq8fFRWFRYsWVWmPi4uDqalpve+rMq5HpWcWaTRekz+U9enLuTm3LvTn3Jybc3Nuzv3vmPvQL0eRfdlC0hhNlJSUaNRPcgF99+5dfPHFF9i2bRt+/fVXODs7Y/LkyZg4cSKUSqWkuSIiIqotMh+WnJwMLy8vqWFCLpdj3759mDRpEqytrWFgYICBAwdi8ODBav2Cg4PFX3fu3Bnt2rWDl5cXfv/9d3h6egIAZDJZlfkFQai2vVJYWBjmzJkjHlc+gfb392+QJ9BOaVfx3W98As25m8bcuhQL5+bcnJtzc+6mN/cA374N9gRaExoX0MeOHcO2bdvw+eefo6ysDIGBgfjxxx8f66nzjBkzMHr06Fr7uLq61nv+Hj16IDU1FQUFBSgrK4OtrS169+5da0Hu6ekJuVyO8+fPw9PTEw4ODsjLy6vSLz8/H/b29jXOY2RkBCMjoyrtcrm81l006lLTeM8uLrBtaa72tuqj7Fpa4IsND/7B8OLrmzTqa2DQDOXlFRr359ycu6nFwrk5N+fm3Jy76c3dUFvaaVqjaXzlZ555BikpKYiMjER2djZ279792Es2bGxs4OHhUeuPsbHxY10DABQKBWxtbXH+/HmkpKRgxIgRNfZNS0uDSqUSv6ro7e2NgoICnDhxQuxz/PhxFBQUwMfH57Fj0xYDg2YIfe25WvuEvNYfBgbNJPXl3Jy7IebWpVg4N+fm3JybczfNuRuTxi8RPrykoTFkZWXh5s2bOHDgAD744AP89ttvAIC2bdvC3NwcwIN1z1FRURg5ciQA4IsvvoCtrS2cnZ1x+vRphISEoEePHti378FSh4sXL2Lnzp0YMmQIbGxscPbsWcydOxcmJiZITk6GgYEBgAfb2GVnZyM6OhrAg23sXFxcdG4bO6D6fRPtWlog5LX+Gu3JWFNfzs25G2JuXYqFc3Nuzs25OXfTnFubGmQf6MYUFBSE7du3V2k/fPgwfH19ATxYq7xt2zYEBQUBANauXYsPPvgAeXl5cHR0xIQJE7Bw4UIYGhoCAK5cuYJx48bhzJkzKC4uhlKpxNChQxEeHg5ra2vxGjdv3qzyIZWPPvpIJz+kAjTtLw79G+b+/fRlHPrlKAb49uWXCHUslvrMrWk+dS1uzl21P3OpP3Mzl/ozt5S/M7VB7wropu5JFtCk25hL/cJ86g/mUn8wl/rjSeeyQT6kQkRERET0b8cCmoiIiIhIgnoV0Pfv38dPP/2E6OhoFBU9+IBHdnY2iotr3nKEiIiIiEgfSP6QyuXLlxEQEICsrCyUlpbCz88PFhYWWL58Oe7du4eNGzc2RJxERERERDpB8hPokJAQeHl54datWzAxMRHbR44ciUOHDmk1OCIiIiIiXSP5CfSRI0dw9OhRcSu4Si4uLvjnn3+0FhgRERERkS6S/AS6oqIC5eXlVdqvXr0KCwsLrQRFRERERKSrJBfQfn5+WL16tXgsk8lQXFyM8PBwDBkyRJuxERERERHpHMlLOFatWoX+/fujY8eOuHfvHsaMGYPz58/DxsYGu3fvbogYiYiIiIh0huQC2snJCampqdi9ezd+//13VFRUYNKkSRg7dqzaS4VERERERPpIcgFdUlICU1NTvPbaa3jttdcaIiYiIiIiIp0leQ20nZ0dxo0bhx9//BEVFRUNERMRERERkc6SXEB/+umnKC0txciRI+Hk5ISQkBAkJyc3RGxERERERDpHcgH9wgsv4IsvvkBeXh6ioqKQnp4OHx8fPPXUU1i8eHFDxEhEREREpDMkF9CVLCwsMHHiRMTFxeGPP/6AmZkZFi1apM3YiIiIiIh0Tr0L6Hv37uHzzz9HYGAgPD09cePGDbz55pvajI2IiIiISOdI3oUjLi4OO3fuxNdffw0DAwO8+OKL+PHHH9GvX7+GiI+IiIiISKdILqADAwMxdOhQbN++HUOHDoVcLm+IuIiIiIiIdJLkAjo3NxeWlpYNEQsRERERkc7TqIAuLCxUK5oLCwtr7MvimoiIiIj0mUYFtJWVFXJycmBnZ4cWLVpAJpNV6SMIAmQyGcrLy7UeJBERERGRrtCogP75559hbW0NADh8+HCDBkREREREpMs0KqAf3mHDzc0NSqWyylNoQRBw5coV7UZHRERERKRjJO8D7ebmhvz8/CrtN2/ehJubm1aCIiIiIiLSVZIL6Mq1zo8qLi6GsbGxVoIiIiIiItJVGm9jN2fOHACATCbDwoULYWpqKp4rLy/H8ePH0a1bN60HWCkyMhLff/89UlNTYWhoiNu3b9c5Ji8vD2+99Rbi4uJw+/ZtPPvss1i3bh3atWsHALh06VKNT80///xzjBo1CgDg6uqKy5cvq51/66238P777z/eTRERERFRk6NxAX3q1CkAD55Anz59GoaGhuI5Q0NDPP300w36Ke+ysjKMGjUK3t7e2Lp1a539BUFAYGAg5HI5vvnmG1haWmLlypUYOHAgzp49CzMzMyiVSuTk5KiN27RpE5YvX47BgwertS9evBjBwcHisbm5uXZujIiIiIiaFI0L6MrdNyZOnIg1a9Y88f2eFy1aBACIiYnRqP/58+eRlJSEM2fOoFOnTgCA9evXw87ODrt378bkyZNhYGAABwcHtXH79+/Hyy+/XKVAtrCwqNKXiIiIiP59JH+JcPXq1bh//36V9ps3b6J58+Y68yGV0tJSAFBbl21gYABDQ0McOXIEkydPrjLm5MmTSE1Nxccff1zl3LJly7BkyRIolUqMGjUK8+bNU3sKX931K2MA/vfxGZVKBZVKJfl+KsfUZyzpFuZSvzCf+oO51B/Mpf540rnU9DqSC+jRo0fj+eefx/Tp09XaP//8cxw4cAAHDx6UOmWD8PDwgIuLC8LCwhAdHQ0zMzOsXLkSubm5VZZtVNq6dSs6dOgAHx8ftfaQkBB4enrCysoKJ06cQFhYGDIzM7Fly5Yarx8VFSU+NX9YXFyc2vpxqeLj4+s9lnQLc6lfmE/9wVzqD+ZSfzypXJaUlGjUTyYIgiBlYmtraxw9ehQdOnRQaz937hz69u2LGzduaDxXREREtUXmw5KTk+Hl5SUex8TEIDQ0VKOXCE+ePIlJkybhjz/+gIGBAQYOHIhmzR5sPPJooX/37l04Ojpi4cKFmDt3bq3z7tu3Dy+++CKuX7+Oli1bVtunuifQSqUS169fr9dTepVKhfj4ePj5+UEul0seT7qDudQvzKf+YC71B3OpP550LgsLC2FjY4OCgoJa6zXJT6BLS0urXcKhUqlw9+5dSXPNmDEDo0ePrrWPq6urpDkf1qNHD6SmpqKgoABlZWWwtbVF79691QrySl9++SVKSkowYcKEOuft06cPAODChQs1FtBGRkYwMjKq0i6Xyx/rD8DjjifdwVzqF+ZTfzCX+oO51B9PKpeaXkNyAd2zZ09s2rQJ69atU2vfuHEjevToIWkuGxsb2NjYSA1BMoVCAeDBi4UpKSlYsmRJlT5bt27F8OHDYWtrW+d8lTuSODo6ajdQIiIiItJ5kgvoyMhIDBw4EH/88QcGDBgAADh06BCSk5MRFxen9QArZWVl4ebNm8jKykJ5eTlSU1MBAG3bthV3zPDw8EBUVBRGjhwJAPjiiy9ga2sLZ2dnnD59GiEhIQgMDIS/v7/a3BcuXMCvv/5a7frtxMREJCUloX///lAoFEhOTsbs2bMxfPhwODs7N9j9EhEREZFuklxA9+3bF4mJiVi+fDk+//xzmJiYoGvXrti6dav4gZKG8O6772L79u3icffu3QE82F7P19cXAJCRkYGCggKxT05ODubMmYO8vDw4OjpiwoQJWLhwYZW5P/nkE7Rq1apKYQ08WIqxd+9eLFq0CKWlpXBxcUFwcDDmz5+v5TskIiIioqZAcgENAN26dcOuXbu0HUutYmJi6twD+tH3IWfNmoVZs2bVOffSpUuxdOnSas95enoiKSlJ4ziJiIiISL81q8+gixcv4r///S/GjBmDa9euAQBiY2ORlpam1eCIiIiIiHSN5AI6ISEBXbp0wfHjx7Fv3z4UFxcDAP7880+Eh4drPUAiIiIiIl0iuYB+++238d577yE+Pl7tS3z9+/dHYmKiVoMjIiIiItI1kgvo06dPi7tcPMzW1lbSR1SIiIiIiJoiyQV0ixYtqv0U9qlTp9CqVSutBEVEREREpKskF9BjxozBW2+9hdzcXMhkMlRUVODo0aN48803NfqKHxERERFRUya5gI6MjISzszNatWqF4uJidOzYEc8++yx8fHzw3//+tyFiJCIiIiLSGZL3gZbL5di5cycWL16MU6dOoaKiAt27d2/Qj6gQEREREemKen1IBQDc3d3h7u6uzViIiIiIiHSeRgX0nDlzsGTJEpiZmWHOnDm19jU3N0enTp3w4osvwsDAQCtBEhERERHpCo0K6FOnTkGlUom/rk1paSnWrFmD77//Hp9++unjR0hEREREpEM0KqAPHz5c7a9rkpKSggEDBtQ/KiIiIiIiHSV5F46HCYIAQRCqtHft2pVPn4mIiIhIL9WrgN66dSs6d+4MY2NjGBsbo3PnztiyZYt43tDQECNGjNBakEREREREukLyLhwLFy7EqlWrMHPmTHh7ewMAEhMTMXv2bFy6dAnvvfee1oMkIiIiItIVkgvoDRs2YPPmzXjllVfEtuHDh6Nr166YOXMmC2giIiIi0muSl3CUl5fDy8urSnuPHj1w//59rQRFRERERKSrJBfQ48aNw4YNG6q0b9q0CWPHjtVKUEREREREukrjD6lUkslk2LJlC+Li4tCnTx8AQFJSEq5cuYIJEyY0TJRERERERDpC4w+pPKxHjx4AgIsXLwIAbG1tYWtri7S0NC2HR0RERESkWyR/SIWIiIiI6N9M8i4cAHD79m1cuHABMpkM7u7uaNGihZbDIiIiIiLSTZJeIrx06RKGDh0KGxsb9O7dG7169YKNjQ2GDRuGS5cuNVCIRERERES6Q+Mn0FeuXEGfPn0gl8uxZMkSdOjQAYIgID09HRs2bIC3tzeSk5PRunXrhoyXiIiIiKhRaVxAh4eHo3379vjxxx9hbGwsto8cORKzZ89GQEAAwsPDsXXr1gYJlIiIiIhIF2i8hCM2NhaRkZFqxXMlExMTLFmyBD/88INWg6t06dIlTJo0CW5ubjAxMYG7uzvCw8NRVlZW6zhBEBAREQEnJyeYmJjA19e3yk4hpaWlmDlzJmxsbGBmZobhw4fj6tWran1u3bqF8ePHQ6FQQKFQYPz48bh9+7a2b5OIiIiImgCNC+gbN27A1dW1xvNt2rTBjRs3tBFTFefOnUNFRQWio6ORlpaGVatWYePGjViwYEGt45YvX46VK1fio48+QnJyMhwcHODn54eioiKxT2hoKPbv3489e/bgyJEjKC4uxrBhw1BeXi72GTNmDFJTUxEbG4vY2FikpqZi/PjxDXKvRERERKTbNF7C4eTkhLS0tBrXOJ85cwaOjo5aC+xhAQEBCAgIEI/btGmDjIwMbNiwAStWrKh2jCAIWL16Nd555x288MILAIDt27fD3t4eu3btwtSpU1FQUICtW7fis88+w8CBAwEAO3bsgFKpxE8//YRBgwYhPT0dsbGxSEpKQu/evQEAmzdvhre3NzIyMtC+ffsGuWciIiIi0k0aF9AjRozAvHnz4OnpCVtbW7Vz165dw1tvvYXAwEBtx1ejgoICWFtb13g+MzMTubm58Pf3F9uMjIzQr18/HDt2DFOnTsXJkyehUqnU+jg5OaFz5844duwYBg0ahMTERCgUCrF4BoA+ffpAoVDg2LFjNRbQpaWlKC0tFY8LCwsBACqVCiqVSvL9Vo6pz1jSLcylfmE+9QdzqT+YS/3xpHOp6XUkvUR48OBBuLu7Y9y4cfDw8AAAnD17Frt27YKDgwPefffd+kUr0cWLF7Fu3Tp8+OGHNfbJzc0FANjb26u129vb4/Lly2IfQ0NDWFlZVelTOT43Nxd2dnZV5rezsxP7VCcqKgqLFi2q0h4XFwdTU9Max9UlPj6+3mNJtzCX+oX51B/Mpf5gLvXHk8plSUmJRv00LqCtrKxw/PhxLFiwAHv27BFfomvRogXGjBmDyMjIWp8IVyciIqLaIvNhycnJ8PLyEo+zs7MREBCAUaNGYfLkyXVeQyaTqR0LglCl7VGP9qmuf13zhIWFYc6cOeJxYWEhlEol/P39YWlpWWfcj1KpVIiPj4efnx/kcrnk8aQ7mEv9wnzqD+ZSfzCX+uNJ57JyxUBdJH2J0MrKChs2bMD69euRn58PALC1ta2zIK3JjBkzMHr06Fr7PPziYnZ2Nvr37w9vb29s2rSp1nEODg4AHjxBfnht9rVr18Sn0g4ODigrK8OtW7fUnkJfu3YNPj4+Yp+8vLwq8+fn51d5uv0wIyMjGBkZVWmXy+WP9QfgcceT7mAu9QvzqT+YS/3BXOqPJ5VLTa9Rr095y2Syapc1SGVjYwMbGxuN+v7zzz/o378/evTogW3btqFZs9o3EHFzc4ODgwPi4+PRvXt3AEBZWRkSEhKwbNkyAECPHj0gl8sRHx+Pl156CQCQk5ODM2fOYPny5QAAb29vFBQU4MSJE+jVqxcA4Pjx4ygoKBCLbCIiIiL695D0Ke/Gkp2dDV9fXyiVSqxYsQL5+fnIzc2tsgbZw8MD+/fvB/CgyA8NDcXSpUuxf/9+nDlzBkFBQTA1NcWYMWMAAAqFApMmTcLcuXNx6NAhnDp1CuPGjUOXLl3EXTk6dOiAgIAABAcHIykpCUlJSQgODsawYcO4AwcRERHRv1C9nkA/aXFxcbhw4QIuXLhQZRs9QRDEX2dkZKCgoEA8nj9/Pu7evYvp06fj1q1b6N27N+Li4mBhYSH2WbVqFZo3b46XXnoJd+/exYABAxATEwMDAwOxz86dOzFr1ixxt47hw4fjo48+aqjbJSIiIiId1iQK6KCgIAQFBdXZ7+FiGnjwFDoiIgIRERE1jjE2Nsa6deuwbt26GvtYW1tjx44dmoZLRERERHpM8hKOTz/9VG1/40plZWX49NNPtRIUEREREZGuklxAT5w4UW2ZRKWioiJMnDhRK0EREREREekqyQV0TfsfX716FQqFQitBERERERHpKo3XQHfv3h0ymQwymQwDBgxA8+b/G1peXo7MzEwEBAQ0SJBERERERLpC4wI6MDAQAJCamopBgwbB3NxcPGdoaAhXV1f85z//0XqARERERES6ROMCOjw8HMCDLwOOHj262q/sERERERHpO8lroJ977jnxM94AcOLECYSGhtb5aW0iIiIiIn0guYAeM2YMDh8+DADIzc3FwIEDceLECSxYsACLFy/WeoBERERERLpEcgF95swZ9OrVCwDw+eefo0uXLjh27Bh27dqFmJgYbcdHRERERKRTJBfQKpVKXP/8008/Yfjw4QAADw8P5OTkaDc6IiIiIiIdI7mA7tSpEzZu3IjffvsN8fHx4tZ12dnZaNmypdYDJCIiIiLSJZIL6GXLliE6Ohq+vr545ZVX8PTTTwMADhw4IC7tICIiIiLSVxpvY1fJ19cX169fR2FhIaysrMT2KVOmwNTUVKvBERERERHpGslPoIEHn/M+efIkoqOjUVRUBODBx1RYQBMRERGRvpP8BPry5csICAhAVlYWSktL4efnBwsLCyxfvhz37t3Dxo0bGyJOIiIiIiKdIPkJdEhICLy8vHDr1i2YmJiI7SNHjsShQ4e0GhwRERERka6R/AT6yJEjOHr0KAwNDdXaXVxc8M8//2gtMCIiIiIiXST5CXRFRQXKy8urtF+9ehUWFhZaCYqIiIiISFdJLqD9/PywevVq8Vgmk6G4uBjh4eEYMmSINmMjIiIiItI5kpdwrFq1Cv3790fHjh1x7949jBkzBufPn4eNjQ12797dEDESEREREekMyQW0k5MTUlNTsWfPHpw8eRIVFRWYNGkSxo4dq/ZSIRERERGRPpJcQAOAiYkJJk6ciIkTJ2o7HiIiIiIinSa5gL5x4wZatmwJALhy5Qo2b96Mu3fv4vnnn8ezzz6r9QCJiIiIiHSJxi8Rnj59Gq6urrCzs4OHhwdSU1PRs2dPrFq1Cps2bcJzzz2Hr7/+ugFDJSIiIiJqfBoX0PPnz0eXLl2QkJAAX19fDBs2DEOGDEFBQQFu3bqFqVOn4v3332/IWImIiIiIGp3GBXRycjIiIyPxzDPPYMWKFcjOzsb06dPRrFkzNGvWDDNnzsS5c+caJMhLly5h0qRJcHNzg4mJCdzd3REeHo6ysrJaxwmCgIiICDg5OcHExAS+vr5IS0sTz9+8eRMzZ85E+/btYWpqCmdnZ8yaNQsFBQVq87i6ukImk6n9vP322w1yr0RERESk2zReA33z5k04ODgAAMzNzWFmZgZra2vxvJWVFYqKirQfIYBz586hoqIC0dHRaNu2Lc6cOYPg4GDcuXMHK1asqHHc8uXLsXLlSsTExOCpp57Ce++9Bz8/P2RkZMDCwgLZ2dnIzs7GihUr0LFjR1y+fBnTpk1DdnY2vvzyS7W5Fi9ejODgYPHY3Ny8Qe6ViIiIiHSbpJcIZTJZrccNJSAgAAEBAeJxmzZtkJGRgQ0bNtRYQAuCgNWrV+Odd97BCy+8AADYvn077O3tsWvXLkydOhWdO3fGvn37xDHu7u6IjIzEuHHjcP/+fTRv/r/fHgsLC/EfEERERET07yWpgA4KCoKRkREA4N69e5g2bRrMzMwAAKWlpdqPrhYFBQVqT8AflZmZidzcXPj7+4ttRkZG6NevH44dO4apU6fWOK+lpaVa8QwAy5Ytw5IlS6BUKjFq1CjMmzcPhoaGNV6/tLRU7feksLAQAKBSqaBSqTS6x4dVjqnPWNItzKV+YT71B3OpP5hL/fGkc6npdTQuoF999VW143HjxlXpM2HCBE2neywXL17EunXr8OGHH9bYJzc3FwBgb2+v1m5vb4/Lly9XO+bGjRtYsmRJleI6JCQEnp6esLKywokTJxAWFobMzExs2bKlxutHRUVh0aJFVdrj4uJgampa47i6xMfH13ss6RbmUr8wn/qDudQfzKX+eFK5LCkp0aifTBAEoYFjqVFERES1RebDkpOT4eXlJR5nZ2ejX79+6NevX60F7LFjx9C3b19kZ2fD0dFRbA8ODsaVK1cQGxur1r+wsBD+/v6wsrLCgQMHIJfLa5x73759ePHFF3H9+nVxT+xHVfcEWqlU4vr167C0tKz1nqujUqkQHx8PPz+/WmMj3cdc6hfmU38wl/qDudQfTzqXhYWFsLGxEVck1KReXyLUlhkzZmD06NG19nF1dRV/nZ2djf79+8Pb2xubNm2qdVzleuXc3Fy1AvratWtVnkoXFRUhICAA5ubm2L9/f50J6tOnDwDgwoULNRbQRkZG4nKXh8nl8sf6A/C440l3MJf6hfnUH8yl/mAu9ceTyqWm12jUAtrGxgY2NjYa9f3nn3/Qv39/9OjRA9u2bUOzZrXvwOfm5gYHBwfEx8eje/fuAICysjIkJCRg2bJlYr/CwkIMGjQIRkZGOHDgAIyNjeuM5dSpUwCgVpgTERER0b9DoxbQmsrOzoavry+cnZ2xYsUK5Ofni+ce3hnDw8MDUVFRGDlyJGQyGUJDQ7F06VK0a9cO7dq1w9KlS2FqaooxY8YAePDk2d/fHyUlJdixYwcKCwvFl/1sbW1hYGCAxMREJCUloX///lAoFEhOTsbs2bMxfPhwODs7P9nfCCIiIiJqdE2igI6Li8OFCxdw4cIFtG7dWu3cw0u4MzIy1D6CMn/+fNy9exfTp0/HrVu30Lt3b8TFxcHCwgIAcPLkSRw/fhwA0LZtW7V5MzMz4erqCiMjI+zduxeLFi1CaWkpXFxcEBwcjPnz5zfU7RIRERGRDmsSBXRQUBCCgoLq7Pfo+5AymQwRERGIiIiotr+vr2+VMY/y9PREUlKSpqESERERkZ7T+FPeRERERETEApqIiIiISBIW0EREREREErCAJiIiIiKSgAU0EREREZEELKCJiIiIiCRgAU1EREREJAELaCIiIiIiCVhAExERERFJwAKaiIiIiEgCFtBERERERBKwgCYiIiIikoAFNBERERGRBCygiYiIiIgkYAFNRERERCQBC2giIiIiIglYQBMRERERScACmoiIiIhIAhbQREREREQSsIAmIiIiIpKABTQRERERkQQsoImIiIiIJGABTUREREQkAQtoIiIiIiIJWEATEREREUnQJAroS5cuYdKkSXBzc4OJiQnc3d0RHh6OsrKyWscJgoCIiAg4OTnBxMQEvr6+SEtLU+vj6+sLmUym9jN69Gi1Prdu3cL48eOhUCigUCgwfvx43L59W9u3SURERERNQJMooM+dO4eKigpER0cjLS0Nq1atwsaNG7FgwYJaxy1fvhwrV67ERx99hOTkZDg4OMDPzw9FRUVq/YKDg5GTkyP+REdHq50fM2YMUlNTERsbi9jYWKSmpmL8+PFav08iIiIi0n3NGzsATQQEBCAgIEA8btOmDTIyMrBhwwasWLGi2jGCIGD16tV455138MILLwAAtm/fDnt7e+zatQtTp04V+5qamsLBwaHaedLT0xEbG4ukpCT07t0bALB582Z4e3sjIyMD7du319ZtEhEREVET0CQK6OoUFBTA2tq6xvOZmZnIzc2Fv7+/2GZkZIR+/frh2LFjagX0zp07sWPHDtjb22Pw4MEIDw+HhYUFACAxMREKhUIsngGgT58+UCgUOHbsWI0FdGlpKUpLS8XjwsJCAIBKpYJKpZJ8v5Vj6jOWdAtzqV+YT/3BXOoP5lJ/POlcanqdJllAX7x4EevWrcOHH35YY5/c3FwAgL29vVq7vb09Ll++LB6PHTsWbm5ucHBwwJkzZxAWFoY//vgD8fHx4jx2dnZV5rezsxOvUZ2oqCgsWrSoSntcXBxMTU1rv8FaVMZFTR9zqV+YT/3BXOoP5lJ/PKlclpSUaNSvUQvoiIiIaovMhyUnJ8PLy0s8zs7ORkBAAEaNGoXJkyfXeQ2ZTKZ2LAiCWltwcLD4686dO6Ndu3bw8vLC77//Dk9Pz2rnqG6eR4WFhWHOnDnicWFhIZRKJfz9/WFpaVln3I9SqVSIj4+Hn58f5HK55PGkO5hL/cJ86g/mUn8wl/rjSeeycsVAXRq1gJ4xY0aVHS8e5erqKv46Ozsb/fv3h7e3NzZt2lTruMo1zbm5uXB0dBTbr127VuWp9MM8PT0hl8tx/vx5eHp6wsHBAXl5eVX65efn1zqPkZERjIyMqrTL5fLH+gPwuONJdzCX+oX51B/Mpf5gLvXHk8qlptdo1ALaxsYGNjY2GvX9559/0L9/f/To0QPbtm1Ds2a1byBSuSwjPj4e3bt3BwCUlZUhISEBy5Ytq3FcWloaVCqVWHR7e3ujoKAAJ06cQK9evQAAx48fR0FBAXx8fDSKnYiIiIj0R5PYxi47Oxu+vr5QKpVYsWIF8vPzkZubW2UNsoeHB/bv3w/gwbKL0NBQLF26FPv378eZM2cQFBQEU1NTjBkzBsCDtdSLFy9GSkoKLl26hIMHD2LUqFHo3r07+vbtCwDo0KEDAgICEBwcjKSkJCQlJSE4OBjDhg3jDhxERERE/0JN4iXCuLg4XLhwARcuXEDr1q3VzgmCIP46IyMDBQUF4vH8+fNx9+5dTJ8+Hbdu3ULv3r0RFxcn7rBhaGiIQ4cOYc2aNSguLoZSqcTQoUMRHh4OAwMDcZ6dO3di1qxZ4o4ew4cPx0cffdSQt0xEREREOqpJFNBBQUEICgqqs9/DxTTw4Cl0REQEIiIiqu2vVCqRkJBQ57zW1tbYsWOHJqESERERkZ5rEks4iIiIiIh0BQtoIiIiIiIJmsQSDn1QubxE0/0FH6VSqVBSUoLCwkJuydPEMZf6hfnUH8yl/mAu9ceTzmVlnfbosuBHsYB+QoqKigA8WHdNRERERLqrqKgICoWixvMyoa4Sm7SioqIC2dnZsLCwqPULhjWp/JLhlStX6vUlQ9IdzKV+YT71B3OpP5hL/fGkcykIAoqKiuDk5FTrN0f4BPoJadasWZUt+OrD0tKS/2OgJ5hL/cJ86g/mUn8wl/rjSeaytifPlfgSIRERERGRBCygiYiIiIgkYAHdRBgZGSE8PBxGRkaNHQo9JuZSvzCf+oO51B/Mpf7Q1VzyJUIiIiIiIgn4BJqIiIiISAIW0EREREREErCAJiIiIiKSgAU0EREREZEELKCbiPXr18PNzQ3Gxsbo0aMHfvvtt8YOierw66+/4vnnn4eTkxNkMhm+/vprtfOCICAiIgJOTk4wMTGBr68v0tLSGidYqlVUVBR69uwJCwsL2NnZITAwEBkZGWp9mM+mYcOGDejatav4UQZvb2/88MMP4nnmsWmKioqCTCZDaGio2MZcNh0RERGQyWRqPw4ODuJ5XcwlC+gmYO/evQgNDcU777yDU6dO4f/+7/8wePBgZGVlNXZoVIs7d+7g6aefxkcffVTt+eXLl2PlypX46KOPkJycDAcHB/j5+aGoqOgJR0p1SUhIwBtvvIGkpCTEx8fj/v378Pf3x507d8Q+zGfT0Lp1a7z//vtISUlBSkoKnnvuOYwYMUL8y5h5bHqSk5OxadMmdO3aVa2duWxaOnXqhJycHPHn9OnT4jmdzKVAOq9Xr17CtGnT1No8PDyEt99+u5EiIqkACPv37xePKyoqBAcHB+H9998X2+7duycoFAph48aNjRAhSXHt2jUBgJCQkCAIAvPZ1FlZWQlbtmxhHpugoqIioV27dkJ8fLzQr18/ISQkRBAE/jfZ1ISHhwtPP/10ted0NZd8Aq3jysrKcPLkSfj7+6u1+/v749ixY40UFT2uzMxM5ObmquXVyMgI/fr1Y16bgIKCAgCAtbU1AOazqSovL8eePXtw584deHt7M49N0BtvvIGhQ4di4MCBau3MZdNz/vx5ODk5wc3NDaNHj8bff/8NQHdz2bzRrkwauX79OsrLy2Fvb6/Wbm9vj9zc3EaKih5XZe6qy+vly5cbIyTSkCAImDNnDp555hl07twZAPPZ1Jw+fRre3t64d+8ezM3NsX//fnTs2FH8y5h5bBr27NmD33//HcnJyVXO8b/JpqV379749NNP8dRTTyEvLw/vvfcefHx8kJaWprO5ZAHdRMhkMrVjQRCqtFHTw7w2PTNmzMCff/6JI0eOVDnHfDYN7du3R2pqKm7fvo19+/bh1VdfRUJCgnieedR9V65cQUhICOLi4mBsbFxjP+ayaRg8eLD46y5dusDb2xvu7u7Yvn07+vTpA0D3csklHDrOxsYGBgYGVZ42X7t2rcq/xqjpqHy7mHltWmbOnIkDBw7g8OHDaN26tdjOfDYthoaGaNu2Lby8vBAVFYWnn34aa9asYR6bkJMnT+LatWvo0aMHmjdvjubNmyMhIQFr165F8+bNxXwxl02TmZkZunTpgvPnz+vsf5csoHWcoaEhevTogfj4eLX2+Ph4+Pj4NFJU9Ljc3Nzg4OCglteysjIkJCQwrzpIEATMmDEDX331FX7++We4ubmpnWc+mzZBEFBaWso8NiEDBgzA6dOnkZqaKv54eXlh7NixSE1NRZs2bZjLJqy0tBTp6elwdHTU2f8uuYSjCZgzZw7Gjx8PLy8veHt7Y9OmTcjKysK0adMaOzSqRXFxMS5cuCAeZ2ZmIjU1FdbW1nB2dkZoaCiWLl2Kdu3aoV27dli6dClMTU0xZsyYRoyaqvPGG29g165d+Oabb2BhYSE+CVEoFDAxMRH3n2U+dd+CBQswePBgKJVKFBUVYc+ePfjll18QGxvLPDYhFhYW4jsIlczMzNCyZUuxnblsOt588008//zzcHZ2xrVr1/Dee++hsLAQr776qu7+d9lo+3+QJB9//LHg4uIiGBoaCp6enuL2WaS7Dh8+LACo8vPqq68KgvBga57w8HDBwcFBMDIyEp599lnh9OnTjRs0Vau6PAIQtm3bJvZhPpuG1157TfzfUltbW2HAgAFCXFyceJ55bLoe3sZOEJjLpuTll18WHB0dBblcLjg5OQkvvPCCkJaWJp7XxVzKBEEQGql2JyIiIiJqcrgGmoiIiIhIAhbQREREREQSsIAmIiIiIpKABTQRERERkQQsoImIiIiIJGABTUREREQkAQtoIiIiIiIJWEATEREREUnAApqIiBqUq6srVq9e3dhhEBFpDQtoIiI9EhQUhMDAQACAr68vQkNDn9i1Y2Ji0KJFiyrtycnJmDJlyhOLg4iooTVv7ACIiEi3lZWVwdDQsN7jbW1ttRgNEVHj4xNoIiI9FBQUhISEBKxZswYymQwymQyXLl0CAJw9exZDhgyBubk57O3tMX78eFy/fl0c6+vrixkzZmDOnDmwsbGBn58fAGDlypXo0qULzMzMoFQqMX36dBQXFwMAfvnlF0ycOBEFBQXi9SIiIgBUXcKRlZWFESNGwNzcHJaWlnjppZeQl5cnno+IiEC3bt3w2WefwdXVFQqFAqNHj0ZRUVHD/qYREWmIBTQRkR5as2YNvL29ERwcjJycHOTk5ECpVCInJwf9+vVDt27dkJKSgtjYWOTl5eGll15SG799+3Y0b94cR48eRXR0NACgWbNmWLt2Lc6cOYPt27fj559/xvz58wEAPj4+WL16NSwtLcXrvfnmm1XiEgQBgYGBuHnzJhISEhAfH4+LFy/i5ZdfVut38eJFfP311/juu+/w3XffISEhAe+//34D/W4REUnDJRxERHpIoVDA0NAQpqamcHBwENs3bNgAT09PLF26VGz75JNPoFQq8ddff+Gpp54CALRt2xbLly9Xm/Ph9dRubm5YsmQJXn/9daxfvx6GhoZQKBSQyWRq13vUTz/9hD///BOZmZlQKpUAgM8++wydOnVCcnIyevbsCQCoqKhATEwMLCwsAADjx4/HoUOHEBkZ+Xi/MUREWsAn0ERE/yInT57E4cOHYW5uLv54eHgAePDUt5KXl1eVsYcPH4afnx9atWoFCwsLTJgwATdu3MCdO3c0vn56ejqUSqVYPANAx44d0aJFC6Snp4ttrq6uYvEMAI6Ojrh27ZqkeyUiaih8Ak1E9C9SUVGB559/HsuWLatyztHRUfy1mZmZ2rnLly9jyJAhmDZtGpYsWQJra2scOXIEkyZNgkql0vj6giBAJpPV2S6Xy9XOy2QyVFRUaHwdIqKGxAKaiEhPGRoaory8XK3N09MT+/btg6urK5o31/yvgJSUFNy/fx8ffvghmjV78H9efv7553Ve71EdO3ZEVlYWrly5Ij6FPnv2LAoKCtChQweN4yEiakxcwkFEpKdcXV1x/PhxXLp0CdevX0dFRQXeeOMN3Lx5E6+88gpOnDiBv//+G3FxcXjttddqLX7d3d1x//59rFu3Dn///Tc+++wzbNy4scr1iouLcejQIVy/fh0lJSVV5hk4cCC6du2KsWPH4vfff8eJEycwYcIE9OvXr9plI0REuogFNBGRnnrzzTdhYGCAjh07wtbWFllZWXBycsLRo0dRXl6OQYMGoXPnzggJCYFCoRCfLFenW7duWLlyJZYtW4bOnTtj586diIqKUuvj4+ODadOm4eWXX4atrW2VlxCBB0sxvv76a1hZWeHZZ5/FwIED0aZNG+zdu1fr909E1FBkgiAIjR0EEREREVFTwSfQREREREQSsIAmIiIiIpKABTQRERERkQQsoImIiIiIJGABTUREREQkAQtoIiIiIiIJWEATEREREUnAApqIiIiISAIW0EREREREErCAJiIiIiKSgAU0EREREZEE/w9RJuWAgfucPAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of unique points explored: 50\n",
      "\n",
      "Actual Model Output with Best Parameters: 0.7401418500000001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "####################################\n",
    "\n",
    "function = 7\n",
    "# Read the files\n",
    "X_init = np.load(\"initial_inputs.npy\")\n",
    "y_init = np.load(\"initial_outputs.npy\")\n",
    "queries_file = \"queries.txt\"\n",
    "observations_file = \"observations.txt\"\n",
    "\n",
    "# Read queries data\n",
    "import ast\n",
    "queries_data = []\n",
    "with open(queries_file, 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.replace('array(', 'np.array(')\n",
    "        queries_data.append(eval(line.strip()))\n",
    "\n",
    "# Read observations data\n",
    "observations_data = []\n",
    "with open(observations_file, 'r') as f:\n",
    "    for line in f:\n",
    "        observations_data.append(eval(line.strip()))\n",
    "\n",
    "# Extract the specified sub-arrays from queries\n",
    "X = np.array([q[function - 1] for q in queries_data], dtype='float64')\n",
    "y = np.array([o[function - 1] for o in observations_data])\n",
    "\n",
    "# Find and remove duplicates\n",
    "unique_indices = []\n",
    "seen = set()\n",
    "for i, x in enumerate(X):\n",
    "    x_tuple = tuple(x)  # Convert to tuple for hashability\n",
    "    if x_tuple not in seen:\n",
    "        seen.add(x_tuple)\n",
    "        unique_indices.append(i)\n",
    "\n",
    "# Keep only unique queries and observations\n",
    "X_unique = np.concatenate((X_init, X[unique_indices]))\n",
    "y_unique = np.concatenate((y_init, y[unique_indices]))\n",
    "queries_unique = [queries_data[i] for i in unique_indices]\n",
    "observations_unique = [observations_data[i] for i in unique_indices]\n",
    "\n",
    "# Save cleaned data to new files\n",
    "with open(\"queries_unique.txt\", \"w\") as f:\n",
    "    for query in queries_unique:\n",
    "        f.write(str(query) + \"\\n\")\n",
    "\n",
    "with open(\"observations_unique.txt\", \"w\") as f:\n",
    "    for obs in observations_unique:\n",
    "        f.write(str(obs) + \"\\n\")\n",
    "\n",
    "# Save cleaned numpy arrays\n",
    "np.save(\"initial_inputs_unique.npy\", X_unique)\n",
    "np.save(\"initial_outputs_unique.npy\", y_unique)\n",
    "##############################\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'param1': X_unique[:, 0],\n",
    "    'param2': X_unique[:, 1],\n",
    "    'param3': X_unique[:, 2],\n",
    "    'param4': X_unique[:, 3],\n",
    "    'param5': X_unique[:, 4],\n",
    "    'param6': X_unique[:, 5],\n",
    "    'output': y_unique\n",
    "})\n",
    "#########################\n",
    "\n",
    "# Find the row with the maximum output\n",
    "best_row_max = df.loc[df['output'].idxmax()]\n",
    "print(\"Best hyperparameters (highest output):\")\n",
    "print(best_row_max)\n",
    "############################\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real\n",
    "from skopt.utils import use_named_args\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from skopt.plots import plot_convergence\n",
    "from scipy.stats import qmc\n",
    "\n",
    "# Generate synthetic dataset (replace with your actual data)\n",
    "X_data, y_data = make_classification(\n",
    "    n_samples=1000, n_features=20, n_classes=3, n_informative=15, random_state=42\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_data, y_data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "def evaluate_actual_model(params):\n",
    "    \"\"\"\n",
    "    Evaluate a Random Forest Classifier with given hyperparameters.\n",
    "    Args:\n",
    "        params (dict): Hyperparameters {'param1': value, ..., 'param6': value}\n",
    "    Returns:\n",
    "        float: Scaled accuracy score\n",
    "    \"\"\"\n",
    "    hyperparams = {\n",
    "        'n_estimators': int(10 + params['param1'] * (200 - 10)),  # [10, 200]\n",
    "        'max_depth': int(3 + params['param2'] * (30 - 3)) if params['param2'] < 0.9 else None,  # [3, 30] or None\n",
    "        'min_samples_split': int(2 + params['param3'] * (20 - 2)),  # [2, 20]\n",
    "        'min_samples_leaf': int(1 + params['param4'] * (10 - 1)),  # [1, 10]\n",
    "        'max_features': 0.1 + params['param5'] * (1.0 - 0.1),  # [0.1, 1.0]\n",
    "        'ccp_alpha': params['param6'] * 0.1,  # [0, 0.1]\n",
    "        'random_state': 42\n",
    "    }\n",
    "    model = RandomForestClassifier(**hyperparams)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    # Scale accuracy to match df output range (0 to 2.114691)\n",
    "    accuracy_scaled = accuracy * 2.114691 / 0.9  # Assume accuracy in [0, 0.9]\n",
    "    return accuracy_scaled\n",
    "\n",
    "# Prepare data\n",
    "df = df.drop_duplicates(subset=['param1', 'param2', 'param3', 'param4', 'param5', 'param6', 'output'], keep='first')\n",
    "X = df[['param1', 'param2', 'param3', 'param4', 'param5', 'param6']].values\n",
    "y = df['output'].values\n",
    "\n",
    "# Define best_row_max\n",
    "best_row_max = df.loc[[df['output'].idxmax()]]\n",
    "print(\"\\nBest known point (best_row_max):\")\n",
    "print(best_row_max)\n",
    "\n",
    "# Enrich data with LHS sampling\n",
    "sampler = qmc.LatinHypercube(d=6, seed=42)\n",
    "lhs_samples = sampler.random(n=5)\n",
    "best_point = best_row_max[['param1', 'param2', 'param3', 'param4', 'param5', 'param6']].values[0]\n",
    "new_points = np.clip(best_point + (lhs_samples - 0.5) * 0.1, 0, 1)\n",
    "new_outputs = [evaluate_actual_model(dict(zip([f'param{i+1}' for i in range(6)], point))) for point in new_points]\n",
    "X = np.vstack([X, new_points])\n",
    "y = np.concatenate([y, new_outputs])\n",
    "print(\"\\nAdded 5 new points via LHS sampling\")\n",
    "\n",
    "# Define hyperparameter space\n",
    "space = [Real(0.0, 1.0, name=f'param{i+1}') for i in range(6)]\n",
    "\n",
    "# Train surrogate model\n",
    "surrogate_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit surrogate\n",
    "surrogate_model.fit(X, y)\n",
    "\n",
    "# Objective function\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    param_values = [params[f'param{i+1}'] for i in range(6)]\n",
    "    pred = surrogate_model.predict([param_values])[0]\n",
    "    return -pred  # Negate to maximize\n",
    "\n",
    "# Initial point\n",
    "initial_point = best_row_max[['param1', 'param2', 'param3', 'param4', 'param5', 'param6']].values.flatten().tolist()\n",
    "\n",
    "# Run optimization\n",
    "res = gp_minimize(\n",
    "    objective,\n",
    "    space,\n",
    "    n_calls=50,\n",
    "    n_random_starts=10,\n",
    "    acq_func='EI',\n",
    "    xi=0.5,\n",
    "    x0=[initial_point],\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = dict(zip([f'param{i+1}' for i in range(6)], res.x))\n",
    "print(\"\\nBest Hyperparameters from Bayesian Optimization:\")\n",
    "print(best_params)\n",
    "print(\"Predicted Output:\", -res.fun)\n",
    "\n",
    "# Diagnostics\n",
    "plt.figure(figsize=(8, 4))\n",
    "plot_convergence(res)\n",
    "plt.title(\"Convergence Plot\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Best Objective Value (Negated)\")\n",
    "plt.show()\n",
    "\n",
    "unique_points = len(np.unique(res.x_iters, axis=0))\n",
    "print(f\"\\nNumber of unique points explored: {unique_points}\")\n",
    "\n",
    "# Validate best parameters\n",
    "actual_output = evaluate_actual_model(best_params)\n",
    "print(\"\\nActual Model Output with Best Parameters:\", actual_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
